# 3D face

# ----------------Moving Mnist-------------
观察 G和D中norm的作用

>>>3dmmnist_wmw+_cd20_cc20_new
#标准版 D和G的FC层 都 有 nrom (D只有中间层有norm)

>>>3dmmnist_wmw+_cd20_cc20_noNorm
#取消了GD的fc和conv最后一层的norm, 结果：模式崩溃，单一图片

>>> 3dmmnist_wmw+_cd20_cc20_noNormD
#取消了D的fc和conv最后一层的norm,  结果：模式对应了，但是结果比D加了batch_norm的粗糙, 不过后面恢复了


>>> 3dmmnist_wmw+_cd20_cc20_noNormD_L1
# conLoss 的 mse 去掉平方,  类似WGAN, 不加gp全黑

>>> 3dmmnist_wmw+_cd20_cc20_noNormD_L1_gp
# 原因是wgan的loss一直在增大，只有Clipping才行，但也达不到纳什均衡

	！！！ 结论:只有D_noNorm 和 D_norm的标准mse可行 

>>>3dmmnist_wmw+_cd20_cc20_lamb20_balence
# 对称的norm和activition , conLoss乘以20 结果崩了

>>>3dmmnist_wmw+_cd20_cc20_lamb20_noNormD
# D没有norm，但最后一层有lrelu


>>>3dmmnist_wmw+_cd20_cc20_lamb20_3FC

>>>3dmmnist_wmw+_cd20_cc20_lamb20_3FC_v2
fc层的维度： in和out相等

>>>3dmmnist_wmw+_cd20_cc20_lamb20_2FC